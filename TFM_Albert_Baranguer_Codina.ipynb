{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TFM_Albert_Baranguer_Codina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aeN_N9KLElhA_zN4Q9KSWrmN58mCH0zS",
      "authorship_tag": "ABX9TyMAHdzsD97L4u+Dlf8CvuYX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abaranguer/uoc_tfm/blob/main/TFM_Albert_Baranguer_Codina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmmmR-wrvJwc"
      },
      "source": [
        "# TFM Albert Baranguer i Codina\n",
        "# Entrenament d'una xarxa ResNet18 per a la classificaci√≥ del dataset HAM10000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia8RRIkKzPR6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695a2d5c-57ce-4a28-cf06-f150be222f7c"
      },
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYjOKdJouz1r"
      },
      "source": [
        "!pip install colab_ssh --upgrade --quiet\n",
        "\n",
        "from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n",
        "\n",
        "password='PasswordCloudflaredTfm202122'\n",
        "launch_ssh_cloudflared(password)\n",
        "\n",
        "git_repo = 'https://github.com/abaranguer/uoc_tfm'\n",
        "\n",
        "init_git_cloudflared(repository_url=git_repo + \".git\",\n",
        "         personal_token=\"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\", \n",
        "         branch=\"main\",\n",
        "         email=\"abaranguer@gmail.com\",\n",
        "         username=\"abaranguer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6Ze4B5J8VGa"
      },
      "source": [
        "# dx (classes) - classe to int and viceversa\n",
        "\n",
        "dx_to_int = {\n",
        "    'akiec': 0,\n",
        "    'bcc': 1,\n",
        "    'bkl': 2,\n",
        "    'df': 3,\n",
        "    'nv': 4,\n",
        "    'mel': 5,\n",
        "    'vasc': 6\n",
        "}\n",
        "\n",
        "int_to_dx = [\n",
        "     'akiec',\n",
        "     'bcc',\n",
        "     'bkl',\n",
        "     'df',\n",
        "     'nv',\n",
        "     'mel',\n",
        "     'vasc'\n",
        "]\n",
        "\n",
        "dx_to_description = {\n",
        "    'akiec': 'Actinic Keratoses and Intraepithelial Carcinoma',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'bkl': '\"Benign keratosis\"',\n",
        "    'df': 'Dermatofibroma',\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'vasc': 'Vascular skin lesions'\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IceGVZsY80c2"
      },
      "source": [
        "# dataset analyzer\n",
        "\n",
        "import pandas\n",
        "import time\n",
        "\n",
        "\n",
        "class Ham10000DatasetAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.path = None\n",
        "        self.df = None\n",
        "        self.num_of_images = 0\n",
        "        self.dataset_classes = 0\n",
        "        self.dataset_classes_counts = None\n",
        "\n",
        "    def analyze_path(self, path):\n",
        "        self.path = path\n",
        "        self.df = pandas.read_csv(path)\n",
        "        self.analyze()\n",
        "\n",
        "    def analyze_dataframe(self, df):\n",
        "        self.path = None\n",
        "        self.df = df\n",
        "        self.analyze()\n",
        "\n",
        "    def analyze(self):\n",
        "        self.num_of_images = len(self.df['dx'])\n",
        "        self.dataset_classes = self.df['dx'].unique()\n",
        "        self.dataset_classes_counts = self.df['dx'].value_counts()\n",
        "\n",
        "    def metadata(self):\n",
        "        return self.num_of_images, self.dataset_classes, self.dataset_classes_counts\n",
        "\n",
        "    def show(self, title):\n",
        "        print(f'---- Analyzer. {title} ----\\n')\n",
        "        print(f'num of images: {self.num_of_images}')\n",
        "        print(f'num of classes: {self.dataset_classes}')\n",
        "        for dataset_classe_count in enumerate(self.dataset_classes_counts):\n",
        "            print(\n",
        "                f'\\tclasse: \"{self.dataset_classes[dataset_classe_count[0]]}\"; num of images: {dataset_classe_count[1]};{(100.0 * dataset_classe_count[1] / self.num_of_images): .2f} % of the dataset.')\n",
        "        print('------------------------')\n",
        "\n",
        "    def save_dataframe(self, data_frame, filename):\n",
        "        path = '/content/drive/MyDrive/UOC-TFM/dataframes/'\n",
        "        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n",
        "        filename = path + timestamp + '_' + filename\n",
        "        data_frame.to_pickle(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQEnowD38--g"
      },
      "source": [
        "# dataset splitter\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class Ham10000DatasetSplitter:\n",
        "    def __init__(self, dataset_metadata_path, dataset_images_path,\n",
        "                 percent_val=0.15, percent_test=0.15,\n",
        "                 BATCH_SIZE=100, VAL_BATCH_SIZE=20, TEST_BATCH_SIZE=20):\n",
        "        np.random.seed(0)\n",
        "        analyzer = Ham10000DatasetAnalyzer()\n",
        "        analyzer.analyze_path(dataset_metadata_path)\n",
        "        analyzer.show('FULL DATASET')\n",
        "\n",
        "        df = pandas.read_csv(dataset_metadata_path)\n",
        "        percent_validation = percent_val + percent_test\n",
        "        self.train_set, val_test_set = train_test_split(df, test_size=percent_validation)\n",
        "        percent_test_validation = percent_test / percent_validation\n",
        "        self.validation_set, self.test_set = train_test_split(val_test_set, test_size=percent_test_validation)\n",
        "\n",
        "        analyzer.analyze_dataframe(self.train_set)\n",
        "        analyzer.show('TRAIN SET')\n",
        "        analyzer.save_dataframe(self.train_set, 'dataframe_train_set.pkl')\n",
        "\n",
        "        analyzer.analyze_dataframe(self.validation_set)\n",
        "        analyzer.show('VALIDATION SET')\n",
        "        analyzer.save_dataframe(self.train_set, 'dataframe_validation_set.pkl')\n",
        "\n",
        "        analyzer.analyze_dataframe(self.test_set)\n",
        "        analyzer.show('TEST SET')\n",
        "        analyzer.save_dataframe(self.train_set, 'dataframe_test_set.pkl')\n",
        "\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        '''\n",
        "        '# training data\n",
        "        train_data_transform = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomVerticalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "        '''\n",
        "\n",
        "        self.train_dataset = Ham10000Dataset(self.train_set, dataset_images_path, self.data_transform)\n",
        "        self.validation_dataset = Ham10000Dataset(self.validation_set, dataset_images_path, self.data_transform)\n",
        "        self.test_dataset = Ham10000Dataset(self.test_set, dataset_images_path, self.data_transform)\n",
        "\n",
        "        self.train_dataloader = DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        self.validation_dataloader = DataLoader(\n",
        "            self.validation_dataset,\n",
        "            batch_size=VAL_BATCH_SIZE,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        self.test_dataloader = DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=TEST_BATCH_SIZE,\n",
        "            shuffle=True\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHLExAiI_Pvs"
      },
      "source": [
        "# HAM10000 Dataset\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class Ham10000Dataset(Dataset):\n",
        "    def __init__(self, csv, img_folder, transform):\n",
        "        self.csv = csv\n",
        "        self.transform = transform\n",
        "        self.img_folder = img_folder\n",
        "        self.image_names = self.csv[:]['image_id']\n",
        "        self.labels = np.array(\n",
        "            self.csv.drop(['lesion_id', 'dx_type', 'age', 'sex', 'localization', 'dataset'], axis=1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.img_folder + self.image_names.iloc[index] + '.jpg'\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        image = self.transform(image)\n",
        "        targets = self.labels[index]\n",
        "        return {'image': image,\n",
        "                'image_id': targets[0],\n",
        "                'dx': targets[1],\n",
        "                'label': dx_to_int[targets[1]]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI-KCPfwBiz8"
      },
      "source": [
        "#Resnet18 trainer\n",
        "\n",
        "import time\n",
        "import torch.optim\n",
        "import torchvision.models as models\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "\n",
        "\n",
        "class Ham10000ResNet18Trainer:\n",
        "\n",
        "    def __init__(self, train_dataloader, model, epochs=5):\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.loss = None\n",
        "        self.optimizer = None\n",
        "        self.which_device = \"\"\n",
        "\n",
        "    def run_training(self):\n",
        "        self.loss = CrossEntropyLoss()\n",
        "        self.optimizer = SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "        # select device (GPU or CPU)\n",
        "        self.which_device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f'using {self.which_device} device')\n",
        "        device = torch.device(self.which_device)\n",
        "\n",
        "        for epoch in range(self.epochs):  # loop over the dataset multiple times\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for i, images in enumerate(self.train_dataloader, 0):\n",
        "                inputs = images['image']\n",
        "                labels = images['label']\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                loss_current = self.loss(outputs, labels)\n",
        "                loss_current.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                running_loss += loss_current.item()\n",
        "                print(f'epoch: {epoch}; i : {i}')\n",
        "                if i % 100 == 99:  # print every 100 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' %\n",
        "                          (epoch + 1, i + 1, running_loss / 100))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        print('Finished Training')\n",
        "\n",
        "        timestamp = time.strftime(\"%Y%m%d%H%M%S\")\n",
        "        path = '/content/drive/MyDrive/UOC-TFM/resnet18_parameters/'\n",
        "        trained_model_filename = path + timestamp + '_ham10000_trained_model.pth'\n",
        "        torch.save(self.model.state_dict(), trained_model_filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODDS9XcKB5In"
      },
      "source": [
        "#resnet18 predictor\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "import torch.optim\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class Ham10000ResNet18Predictor:\n",
        "    def __init__(self, model, test_dataloader):\n",
        "        self.model = model\n",
        "        self.test_dataloader = test_dataloader\n",
        "\n",
        "    def run_predictor(self):\n",
        "        images = next(iter(self.test_dataloader))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            images_as_tensors = images['image']\n",
        "            outputs = model(images_as_tensors)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        print('Predicted: ', ' '.join('%5s' % int_to_dx[int(predicted[j])] for j in range(len(predicted))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqHR82oWCJX3"
      },
      "source": [
        "#resnet18 validator\n",
        "\n",
        "import numpy as np\n",
        "import pandas\n",
        "import torch.optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class Ham10000ResNet18Validator:\n",
        "    def __init__(self, model, validation_dataloader):\n",
        "        self.model = model\n",
        "        self.validation_dataloader = validation_dataloader\n",
        "        self.accuracy = 0.0\n",
        "\n",
        "    def run_validation(self):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, images in enumerate(self.validation_dataloader, 0):\n",
        "            inputs = images['image']\n",
        "            labels = images['label']\n",
        "\n",
        "            print(f'batch {i}')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        self.accuracy = 100 * correct / total\n",
        "        print(f'num of correct predicted images (True positives): {correct}')\n",
        "        print(f'num of images : {total}')\n",
        "        print(f'Accuracy of the network on the test images: {self.accuracy: .4f}%')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1DynfZq-SFN"
      },
      "source": [
        "import time\n",
        "\n",
        "def log_time(message):\n",
        "    start_time = time.strftime(\"%Y%m%d - %H%M%S\")\n",
        "    print(f'{message} {start_time}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maAODwJ2FPHt"
      },
      "source": [
        "### Resnet18 Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ5qBK5tCq6X",
        "outputId": "193185ca-2960-466d-9074-f6deb134fbed"
      },
      "source": [
        "matadata_path = '/content/drive/MyDrive/UOC-TFM/dataset/HAM10000_metadata'\n",
        "images_path = '/content/drive/MyDrive/UOC-TFM/dataset/dataset_ham_10000/ham10000/300x225/'\n",
        "\n",
        "print('1 . Splits training, validation and test sets')\n",
        "splitter = Ham10000DatasetSplitter(matadata_path, images_path)\n",
        "train_dataloader = splitter.train_dataloader\n",
        "validation_dataloader = splitter.validation_dataloader\n",
        "test_dataloader = splitter.test_dataloader\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 . Splits training, validation and test sets\n",
            "---- Analyzer. FULL DATASET ----\n",
            "\n",
            "num of images: 10015\n",
            "num of classes: ['bkl' 'nv' 'df' 'mel' 'vasc' 'bcc' 'akiec']\n",
            "\tclasse: \"bkl\"; num of images: 6705; 66.95 % of the dataset.\n",
            "\tclasse: \"nv\"; num of images: 1113; 11.11 % of the dataset.\n",
            "\tclasse: \"df\"; num of images: 1099; 10.97 % of the dataset.\n",
            "\tclasse: \"mel\"; num of images: 514; 5.13 % of the dataset.\n",
            "\tclasse: \"vasc\"; num of images: 327; 3.27 % of the dataset.\n",
            "\tclasse: \"bcc\"; num of images: 142; 1.42 % of the dataset.\n",
            "\tclasse: \"akiec\"; num of images: 115; 1.15 % of the dataset.\n",
            "------------------------\n",
            "---- Analyzer. TRAIN SET ----\n",
            "\n",
            "num of images: 7010\n",
            "num of classes: ['nv' 'bkl' 'bcc' 'akiec' 'vasc' 'df' 'mel']\n",
            "\tclasse: \"nv\"; num of images: 4693; 66.95 % of the dataset.\n",
            "\tclasse: \"bkl\"; num of images: 784; 11.18 % of the dataset.\n",
            "\tclasse: \"bcc\"; num of images: 775; 11.06 % of the dataset.\n",
            "\tclasse: \"akiec\"; num of images: 350; 4.99 % of the dataset.\n",
            "\tclasse: \"vasc\"; num of images: 234; 3.34 % of the dataset.\n",
            "\tclasse: \"df\"; num of images: 103; 1.47 % of the dataset.\n",
            "\tclasse: \"mel\"; num of images: 71; 1.01 % of the dataset.\n",
            "------------------------\n",
            "---- Analyzer. VALIDATION SET ----\n",
            "\n",
            "num of images: 1502\n",
            "num of classes: ['mel' 'nv' 'akiec' 'bkl' 'vasc' 'bcc' 'df']\n",
            "\tclasse: \"mel\"; num of images: 991; 65.98 % of the dataset.\n",
            "\tclasse: \"nv\"; num of images: 182; 12.12 % of the dataset.\n",
            "\tclasse: \"akiec\"; num of images: 156; 10.39 % of the dataset.\n",
            "\tclasse: \"bkl\"; num of images: 79; 5.26 % of the dataset.\n",
            "\tclasse: \"vasc\"; num of images: 49; 3.26 % of the dataset.\n",
            "\tclasse: \"bcc\"; num of images: 25; 1.66 % of the dataset.\n",
            "\tclasse: \"df\"; num of images: 20; 1.33 % of the dataset.\n",
            "------------------------\n",
            "---- Analyzer. TEST SET ----\n",
            "\n",
            "num of images: 1503\n",
            "num of classes: ['nv' 'bcc' 'bkl' 'mel' 'akiec' 'df' 'vasc']\n",
            "\tclasse: \"nv\"; num of images: 1021; 67.93 % of the dataset.\n",
            "\tclasse: \"bcc\"; num of images: 159; 10.58 % of the dataset.\n",
            "\tclasse: \"bkl\"; num of images: 156; 10.38 % of the dataset.\n",
            "\tclasse: \"mel\"; num of images: 85; 5.66 % of the dataset.\n",
            "\tclasse: \"akiec\"; num of images: 44; 2.93 % of the dataset.\n",
            "\tclasse: \"df\"; num of images: 19; 1.26 % of the dataset.\n",
            "\tclasse: \"vasc\"; num of images: 19; 1.26 % of the dataset.\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H11kBV6FD5Gh",
        "outputId": "c2144b67-2d74-4c29-bbd9-27837fd3a8d3"
      },
      "source": [
        "print('2 - create ResNet18 model')\n",
        "model = models.resnet18()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 - create ResNet18 model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRxFR6LBEA_M",
        "outputId": "f6b20604-0934-4872-dead-0232d77b1d2c"
      },
      "source": [
        "print('3 - train model')\n",
        "trainer = Ham10000ResNet18Trainer(train_dataloader, model)\n",
        "\n",
        "log_time('\\tTraining start time:')\n",
        "\n",
        "trainer.run_training()\n",
        "\n",
        "log_time('\\tTraining end time:')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 - train model\n",
            "\tTraining start time: 20211018 - 202332\n",
            "using cpu device\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0; i : 0\n",
            "epoch: 0; i : 1\n",
            "epoch: 0; i : 2\n",
            "epoch: 0; i : 3\n",
            "epoch: 0; i : 4\n",
            "epoch: 0; i : 5\n",
            "epoch: 0; i : 6\n",
            "epoch: 0; i : 7\n",
            "epoch: 0; i : 8\n",
            "epoch: 0; i : 9\n",
            "epoch: 0; i : 10\n",
            "epoch: 0; i : 11\n",
            "epoch: 0; i : 12\n",
            "epoch: 0; i : 13\n",
            "epoch: 0; i : 14\n",
            "epoch: 0; i : 15\n",
            "epoch: 0; i : 16\n",
            "epoch: 0; i : 17\n",
            "epoch: 0; i : 18\n",
            "epoch: 0; i : 19\n",
            "epoch: 0; i : 20\n",
            "epoch: 0; i : 21\n",
            "epoch: 0; i : 22\n",
            "epoch: 0; i : 23\n",
            "epoch: 0; i : 24\n",
            "epoch: 0; i : 25\n",
            "epoch: 0; i : 26\n",
            "epoch: 0; i : 27\n",
            "epoch: 0; i : 28\n",
            "epoch: 0; i : 29\n",
            "epoch: 0; i : 30\n",
            "epoch: 0; i : 31\n",
            "epoch: 0; i : 32\n",
            "epoch: 0; i : 33\n",
            "epoch: 0; i : 34\n",
            "epoch: 0; i : 35\n",
            "epoch: 0; i : 36\n",
            "epoch: 0; i : 37\n",
            "epoch: 0; i : 38\n",
            "epoch: 0; i : 39\n",
            "epoch: 0; i : 40\n",
            "epoch: 0; i : 41\n",
            "epoch: 0; i : 42\n",
            "epoch: 0; i : 43\n",
            "epoch: 0; i : 44\n",
            "epoch: 0; i : 45\n",
            "epoch: 0; i : 46\n",
            "epoch: 0; i : 47\n",
            "epoch: 0; i : 48\n",
            "epoch: 0; i : 49\n",
            "epoch: 0; i : 50\n",
            "epoch: 0; i : 51\n",
            "epoch: 0; i : 52\n",
            "epoch: 0; i : 53\n",
            "epoch: 0; i : 54\n",
            "epoch: 0; i : 55\n",
            "epoch: 0; i : 56\n",
            "epoch: 0; i : 57\n",
            "epoch: 0; i : 58\n",
            "epoch: 0; i : 59\n",
            "epoch: 0; i : 60\n",
            "epoch: 0; i : 61\n",
            "epoch: 0; i : 62\n",
            "epoch: 0; i : 63\n",
            "epoch: 0; i : 64\n",
            "epoch: 0; i : 65\n",
            "epoch: 0; i : 66\n",
            "epoch: 0; i : 67\n",
            "epoch: 0; i : 68\n",
            "epoch: 0; i : 69\n",
            "epoch: 0; i : 70\n",
            "epoch: 1; i : 0\n",
            "epoch: 1; i : 1\n",
            "epoch: 1; i : 2\n",
            "epoch: 1; i : 3\n",
            "epoch: 1; i : 4\n",
            "epoch: 1; i : 5\n",
            "epoch: 1; i : 6\n",
            "epoch: 1; i : 7\n",
            "epoch: 1; i : 8\n",
            "epoch: 1; i : 9\n",
            "epoch: 1; i : 10\n",
            "epoch: 1; i : 11\n",
            "epoch: 1; i : 12\n",
            "epoch: 1; i : 13\n",
            "epoch: 1; i : 14\n",
            "epoch: 1; i : 15\n",
            "epoch: 1; i : 16\n",
            "epoch: 1; i : 17\n",
            "epoch: 1; i : 18\n",
            "epoch: 1; i : 19\n",
            "epoch: 1; i : 20\n",
            "epoch: 1; i : 21\n",
            "epoch: 1; i : 22\n",
            "epoch: 1; i : 23\n",
            "epoch: 1; i : 24\n",
            "epoch: 1; i : 25\n",
            "epoch: 1; i : 26\n",
            "epoch: 1; i : 27\n",
            "epoch: 1; i : 28\n",
            "epoch: 1; i : 29\n",
            "epoch: 1; i : 30\n",
            "epoch: 1; i : 31\n",
            "epoch: 1; i : 32\n",
            "epoch: 1; i : 33\n",
            "epoch: 1; i : 34\n",
            "epoch: 1; i : 35\n",
            "epoch: 1; i : 36\n",
            "epoch: 1; i : 37\n",
            "epoch: 1; i : 38\n",
            "epoch: 1; i : 39\n",
            "epoch: 1; i : 40\n",
            "epoch: 1; i : 41\n",
            "epoch: 1; i : 42\n",
            "epoch: 1; i : 43\n",
            "epoch: 1; i : 44\n",
            "epoch: 1; i : 45\n",
            "epoch: 1; i : 46\n",
            "epoch: 1; i : 47\n",
            "epoch: 1; i : 48\n",
            "epoch: 1; i : 49\n",
            "epoch: 1; i : 50\n",
            "epoch: 1; i : 51\n",
            "epoch: 1; i : 52\n",
            "epoch: 1; i : 53\n",
            "epoch: 1; i : 54\n",
            "epoch: 1; i : 55\n",
            "epoch: 1; i : 56\n",
            "epoch: 1; i : 57\n",
            "epoch: 1; i : 58\n",
            "epoch: 1; i : 59\n",
            "epoch: 1; i : 60\n",
            "epoch: 1; i : 61\n",
            "epoch: 1; i : 62\n",
            "epoch: 1; i : 63\n",
            "epoch: 1; i : 64\n",
            "epoch: 1; i : 65\n",
            "epoch: 1; i : 66\n",
            "epoch: 1; i : 67\n",
            "epoch: 1; i : 68\n",
            "epoch: 1; i : 69\n",
            "epoch: 1; i : 70\n",
            "epoch: 2; i : 0\n",
            "epoch: 2; i : 1\n",
            "epoch: 2; i : 2\n",
            "epoch: 2; i : 3\n",
            "epoch: 2; i : 4\n",
            "epoch: 2; i : 5\n",
            "epoch: 2; i : 6\n",
            "epoch: 2; i : 7\n",
            "epoch: 2; i : 8\n",
            "epoch: 2; i : 9\n",
            "epoch: 2; i : 10\n",
            "epoch: 2; i : 11\n",
            "epoch: 2; i : 12\n",
            "epoch: 2; i : 13\n",
            "epoch: 2; i : 14\n",
            "epoch: 2; i : 15\n",
            "epoch: 2; i : 16\n",
            "epoch: 2; i : 17\n",
            "epoch: 2; i : 18\n",
            "epoch: 2; i : 19\n",
            "epoch: 2; i : 20\n",
            "epoch: 2; i : 21\n",
            "epoch: 2; i : 22\n",
            "epoch: 2; i : 23\n",
            "epoch: 2; i : 24\n",
            "epoch: 2; i : 25\n",
            "epoch: 2; i : 26\n",
            "epoch: 2; i : 27\n",
            "epoch: 2; i : 28\n",
            "epoch: 2; i : 29\n",
            "epoch: 2; i : 30\n",
            "epoch: 2; i : 31\n",
            "epoch: 2; i : 32\n",
            "epoch: 2; i : 33\n",
            "epoch: 2; i : 34\n",
            "epoch: 2; i : 35\n",
            "epoch: 2; i : 36\n",
            "epoch: 2; i : 37\n",
            "epoch: 2; i : 38\n",
            "epoch: 2; i : 39\n",
            "epoch: 2; i : 40\n",
            "epoch: 2; i : 41\n",
            "epoch: 2; i : 42\n",
            "epoch: 2; i : 43\n",
            "epoch: 2; i : 44\n",
            "epoch: 2; i : 45\n",
            "epoch: 2; i : 46\n",
            "epoch: 2; i : 47\n",
            "epoch: 2; i : 48\n",
            "epoch: 2; i : 49\n",
            "epoch: 2; i : 50\n",
            "epoch: 2; i : 51\n",
            "epoch: 2; i : 52\n",
            "epoch: 2; i : 53\n",
            "epoch: 2; i : 54\n",
            "epoch: 2; i : 55\n",
            "epoch: 2; i : 56\n",
            "epoch: 2; i : 57\n",
            "epoch: 2; i : 58\n",
            "epoch: 2; i : 59\n",
            "epoch: 2; i : 60\n",
            "epoch: 2; i : 61\n",
            "epoch: 2; i : 62\n",
            "epoch: 2; i : 63\n",
            "epoch: 2; i : 64\n",
            "epoch: 2; i : 65\n",
            "epoch: 2; i : 66\n",
            "epoch: 2; i : 67\n",
            "epoch: 2; i : 68\n",
            "epoch: 2; i : 69\n",
            "epoch: 2; i : 70\n",
            "epoch: 3; i : 0\n",
            "epoch: 3; i : 1\n",
            "epoch: 3; i : 2\n",
            "epoch: 3; i : 3\n",
            "epoch: 3; i : 4\n",
            "epoch: 3; i : 5\n",
            "epoch: 3; i : 6\n",
            "epoch: 3; i : 7\n",
            "epoch: 3; i : 8\n",
            "epoch: 3; i : 9\n",
            "epoch: 3; i : 10\n",
            "epoch: 3; i : 11\n",
            "epoch: 3; i : 12\n",
            "epoch: 3; i : 13\n",
            "epoch: 3; i : 14\n",
            "epoch: 3; i : 15\n",
            "epoch: 3; i : 16\n",
            "epoch: 3; i : 17\n",
            "epoch: 3; i : 18\n",
            "epoch: 3; i : 19\n",
            "epoch: 3; i : 20\n",
            "epoch: 3; i : 21\n",
            "epoch: 3; i : 22\n",
            "epoch: 3; i : 23\n",
            "epoch: 3; i : 24\n",
            "epoch: 3; i : 25\n",
            "epoch: 3; i : 26\n",
            "epoch: 3; i : 27\n",
            "epoch: 3; i : 28\n",
            "epoch: 3; i : 29\n",
            "epoch: 3; i : 30\n",
            "epoch: 3; i : 31\n",
            "epoch: 3; i : 32\n",
            "epoch: 3; i : 33\n",
            "epoch: 3; i : 34\n",
            "epoch: 3; i : 35\n",
            "epoch: 3; i : 36\n",
            "epoch: 3; i : 37\n",
            "epoch: 3; i : 38\n",
            "epoch: 3; i : 39\n",
            "epoch: 3; i : 40\n",
            "epoch: 3; i : 41\n",
            "epoch: 3; i : 42\n",
            "epoch: 3; i : 43\n",
            "epoch: 3; i : 44\n",
            "epoch: 3; i : 45\n",
            "epoch: 3; i : 46\n",
            "epoch: 3; i : 47\n",
            "epoch: 3; i : 48\n",
            "epoch: 3; i : 49\n",
            "epoch: 3; i : 50\n",
            "epoch: 3; i : 51\n",
            "epoch: 3; i : 52\n",
            "epoch: 3; i : 53\n",
            "epoch: 3; i : 54\n",
            "epoch: 3; i : 55\n",
            "epoch: 3; i : 56\n",
            "epoch: 3; i : 57\n",
            "epoch: 3; i : 58\n",
            "epoch: 3; i : 59\n",
            "epoch: 3; i : 60\n",
            "epoch: 3; i : 61\n",
            "epoch: 3; i : 62\n",
            "epoch: 3; i : 63\n",
            "epoch: 3; i : 64\n",
            "epoch: 3; i : 65\n",
            "epoch: 3; i : 66\n",
            "epoch: 3; i : 67\n",
            "epoch: 3; i : 68\n",
            "epoch: 3; i : 69\n",
            "epoch: 3; i : 70\n",
            "epoch: 4; i : 0\n",
            "epoch: 4; i : 1\n",
            "epoch: 4; i : 2\n",
            "epoch: 4; i : 3\n",
            "epoch: 4; i : 4\n",
            "epoch: 4; i : 5\n",
            "epoch: 4; i : 6\n",
            "epoch: 4; i : 7\n",
            "epoch: 4; i : 8\n",
            "epoch: 4; i : 9\n",
            "epoch: 4; i : 10\n",
            "epoch: 4; i : 11\n",
            "epoch: 4; i : 12\n",
            "epoch: 4; i : 13\n",
            "epoch: 4; i : 14\n",
            "epoch: 4; i : 15\n",
            "epoch: 4; i : 16\n",
            "epoch: 4; i : 17\n",
            "epoch: 4; i : 18\n",
            "epoch: 4; i : 19\n",
            "epoch: 4; i : 20\n",
            "epoch: 4; i : 21\n",
            "epoch: 4; i : 22\n",
            "epoch: 4; i : 23\n",
            "epoch: 4; i : 24\n",
            "epoch: 4; i : 25\n",
            "epoch: 4; i : 26\n",
            "epoch: 4; i : 27\n",
            "epoch: 4; i : 28\n",
            "epoch: 4; i : 29\n",
            "epoch: 4; i : 30\n",
            "epoch: 4; i : 31\n",
            "epoch: 4; i : 32\n",
            "epoch: 4; i : 33\n",
            "epoch: 4; i : 34\n",
            "epoch: 4; i : 35\n",
            "epoch: 4; i : 36\n",
            "epoch: 4; i : 37\n",
            "epoch: 4; i : 38\n",
            "epoch: 4; i : 39\n",
            "epoch: 4; i : 40\n",
            "epoch: 4; i : 41\n",
            "epoch: 4; i : 42\n",
            "epoch: 4; i : 43\n",
            "epoch: 4; i : 44\n",
            "epoch: 4; i : 45\n",
            "epoch: 4; i : 46\n",
            "epoch: 4; i : 47\n",
            "epoch: 4; i : 48\n",
            "epoch: 4; i : 49\n",
            "epoch: 4; i : 50\n",
            "epoch: 4; i : 51\n",
            "epoch: 4; i : 52\n",
            "epoch: 4; i : 53\n",
            "epoch: 4; i : 54\n",
            "epoch: 4; i : 55\n",
            "epoch: 4; i : 56\n",
            "epoch: 4; i : 57\n",
            "epoch: 4; i : 58\n",
            "epoch: 4; i : 59\n",
            "epoch: 4; i : 60\n",
            "epoch: 4; i : 61\n",
            "epoch: 4; i : 62\n",
            "epoch: 4; i : 63\n",
            "epoch: 4; i : 64\n",
            "epoch: 4; i : 65\n",
            "epoch: 4; i : 66\n",
            "epoch: 4; i : 67\n",
            "epoch: 4; i : 68\n",
            "epoch: 4; i : 69\n",
            "epoch: 4; i : 70\n",
            "Finished Training\n",
            "\tTraining end time: 20211018 - 235828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a748jq6kp0zc"
      },
      "source": [
        "√âs dir, amb 5 epochs, el training ha trigat unes 3h i mitja (23h 58m 28s - 20h 23h 32s).\n",
        "\n",
        "En aquell moment, l'ordinador estava desat√®s, de forma que la sessi√≥ va caducar per inactivitat.\n",
        "\n",
        "Tanmateix, el training i els dataframes estan desats al Google Drive.\n",
        "\n",
        "Per tant, els passos seg√ºents els realitzo recuperant el traning i els dataframes del Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRbmTmhEQXR"
      },
      "source": [
        "print('4 - validate model')\n",
        "validator = Ham10000ResNet18Validator(model, validation_dataloader)\n",
        "validator.run_validation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMgDxnoEWCd"
      },
      "source": [
        "print('5 - make predictions')\n",
        "predictor = Ham10000ResNet18Predictor(model, test_dataloader)\n",
        "predictor.run_predictor()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}